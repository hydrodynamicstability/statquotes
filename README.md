## Statistics

- "It is easy to lie with statistics, but it is easier to lie without them." 

  - Frederick Mosteller

- "Statistics is more a way of thinking or reasoning than a bunch of prescriptions for beating data to elicit answers."

  - C. R. Rao (1997)
  
  - *Statistics and Truth:  Putting Chance to Work*.  World Scientific.
  
- "Statistics is nothing more than a trivial exercise if it does not address real-world problems."

  - Colin Mallows (2006)
  
  - Tukey's paper after 40 years.  *Technometrics*, 48:  319-325.
  
- "In particular, statisticians and other quantitatively trained personnel must avoid being seduced into believing that statistical thinking and tools are the total solution.  Statistics is certainly necessary but it is not sufficient.  Experience has shown that the use of statistical techniques has a limited impact unless its use is supported by a larger system such as total quality.  By institutionalizing total quality we help ensure the proper role and use of quality technology."
 
  - Ronald D. Snee (1986)
  
  - In pursuit of total quality. *Quality Progress*, 20 (8): 25-31.

- "The aim of basic research is not to produce statistically valid results but to study new phenomena. An evaluation of experimental findings depends on many factors, such as compatibility with other results, predictions to which it leads and so on—such evidence can rarely be evaluated statistically."

  - William Feller (1969)
  
  - Are Life Scientists Overawed by Statistics? (Too Much Faith in Statistics), *Scientific Research*, 4: 24–29.

- "The most important maxim for data analysis to heed, and one which many statisticians seem to have shunned, is this:  'Far better an approximate answer to the *right* question, which is often vague, than an *exact* answer to the wrong question, which can always be made precise.'  Data analysis must progress by approximate answers, at best, since its knowledge of what the problem really is will at best be approximate.  It would be a mistake not to face up to this fact, for by denying it, we would deny ourselves the use of a great body of approximate knowledge, as well as failing to maintain alertness to the possible importance in each particular instance of particular ways in which our knowledge is incomplete."

  - John W. Tukey (1962)

  - The future of data analysis.  *Annals of Mathematical Statistics*, 33:  1-67.

- "Data analysis has its major uses.  They are detective work and guidance counseling.  We should all act accordingly."

  - John W. Tukey (1969)
  
  - Analyzing data:  sanctification or detective work?  *American Psychologist*, 24 (2):  83-91.

## Data

- "\[F\]or without data, everyone is an expert.  Issues that generate great disagreement and controversy are usually those where little factual data exist."

  - Ronald D. Snee (1986)
  
  - In pursuit of total quality. *Quality Progress*, 20 (8): 25-31.

- "Data, if it is of poor quality, becomes a pollutant to clear thinking and rational decisions."

  - J. Stuart Hunter (1980)
  
  - The national system of scientific measurement.  *Science*, 210:  869-874.

- "Data are not just numbers, they are numbers with a context."

  - George W. Cobb and David S. Moore (1997)
  
  - Mathematics, statistics, and teaching.  *American Mathematical Monthly*, 104:  801-823.

- "\[T\]he discovery of the irrelevance of past knowledge to the data before us can be one of the great triumphs of science."

  - John W. Tukey (1972)

  - Data analysis, computation, and mathematics.  *Quarterly of Applied Mathematics*, 30:  51-65.
  
- "My experience with data analysis indicates to me that problems with the data themselves are usually more numerous and more serious than problems with methodology."
 
  - John C. Bailar, III (1976)
  
  - Bailar's laws of data analysis.  *Clinical Pharmacology and Therapeutics*, 20:  113-119.

- "In data analysis, a crucial and often bungled decision is the choice of data to be investigated.  It may pay to ignore a massive majority, if it is distorted by systematic errors."

  - Peter J. Huber (2011)

  - *Data Analysis:  What Can Be Learned from the Past 50 Years*.  Wiley.

- "I know of no thoughtful account of scientific research as a dynamic process--I assume psychology is not yet seeking stasis--according to which data analysis should fail to be flexible, or should fail to be a handmaiden rather than a high priestess."

  - John W. Tukey (1969)
  
  - Analyzing data:  sanctification or detective work?  *American Psychologist*, 24 (2):  83-91.

- "I once suggested in discussion at a statistical meeting that it might be well if statisticians looked to see how data was actually analyzed by many sorts of people.  A very eminent and senior statistician rose at once to say that this was a novel idea, that it might have merit, but that young statisticians should be careful not to indulge in it too much, since it might distort their ideas.  *The ideas of data analysis ought to survive a look at how data is analyzed*....If data analysis is to be well done, much of it must be a matter of judgment, and 'theory', whether statistical or non-statistical, will have to guide, not command."

  - John W. Tukey (1962)

  - The future of data analysis.  *Annals of Mathematical Statistics*, 33:  1-67.

- "Instant data analysis is--and will remain--an illusion."

  - John W. Tukey (1969)
  
  - Analyzing data:  sanctification or detective work?  *American Psychologist*, 24 (2):  83-91.

## Experimental design

- "The purpose of statistics in laboratories should be to save labor, time, and expense by efficient experimental designs.  But all too frequently statisticians impose all kinds of nonsensical conditions on the poor biologist or psychologist--conditions which, although they produce unequivocal statistical results, actually hinder him in his research."

  - William Feller (1969)
  
  - Are Life Scientists Overawed by Statistics? (Too Much Faith in Statistics), *Scientific Research*, 4: 24–29.

- "No amount of statistical maneuvering will get very far without some understanding of how the data were produced."

  - Richard A. Berk  & David A. Freedman (2003)
  
  - Statistical assumptions as empirical commitments.  In *Punishment and Social Control:  Essays in Honor of Sheldon Messenger*, 2d ed., ed. by T. G. Blomberg and S. Cohn.  Aldine de Gruyter, pp. 235-254.
  
- "Statistical ideas for producing data to answer specific questions are the most influential contributions of statistics to human knowledge.  Badly designed data production is the most common serious flaw in statistical studies.  Well designed data production allows us to apply standard methods of analysis and reach clear conclusions.  Professional statisticians are paid for their expertise in designing studies; if the study is well designed (and no unanticipated disaster occurred), you don't need a professional to do the analysis.  In other words, the design of data production is *really* important.  If you just say 'Suppose X_1 to X_n are iid observations,' you aren't teaching statistics."

  - George W. Cobb and David S. Moore (1997)
  
  - Mathematics, statistics, and teaching.  *American Mathematical Monthly*, 104:  801-823.

- "Always involved  in good experimental design are the following inherent characteristics:  (1) measurement is always comparative; (2) measurement is what is done, not what should be done.  Good experimental designs use these facts to help accuracy, rather than allowing them to hinder it."

  - John W. Tukey (1953)
  
  - The growth of experimental design in a research laboratory.  In *Research Operations in Industry: Papers Delivered at the Third Annual Conference on Industrial Research, June 1952. With Selected Papers from the First and Second Conferences*, ed. by D. B. Hertz.  Columbia University Press, pp. 303-313.

- "To find out what happens to a system when you interere with it you have to interfere with it (not just passively observe it)."

  - G. E. P. Box (1966)
  
  - Use and abuse of regression.  *Technometrics*, 8:  625-629.

- "Block what you can and randomize what you cannot."

  - George E.P. Box, William G. Hunter, and J. Stuart Hunter (1978)
  
  - *Statistics for Experimenters:  An Introduction to Design, Data Analysis, and Model Building*.  Wiley.
  
- "If your experiment needs statistics, you ought to have done a better experiment."

  - Lord Ernest Rutherford, 1908 Nobel Laureate in Chemistry

## Data description

- "Good statistical description is demanding and challenging work: it requires sound conceptualization, and demands insightfully organizing the data, and effectively communicating the results; not one of those tasks is easy. To mistakenly treat description as ‘routine’ is almost surely to botch the job."

  - Lincoln E. Moses (1992)

  - The reasoning of statistical inference. In *Perspectives on Contemporary Statistics*, ed. by D. C. Hoaglin and D. S. Moore.
Mathematical Association of America, pp. 107–122

- "If one technique of data analysis were to be exalted above all others for its ability to be revealing to the mind in connection with each of many different models, there is little doubt which one would be chosen.  The simple graph has brought more information to the data analyst's mind than any other device.  It specializes in providing indications of expected phenomena.  So long as we have to deal with the relation of a single response to a single stimulus, we can express almost everything qualitative, and much that is quantitative, by a graph.  We may have to plot the differences between observed response and a function of the stimulus against another function of stimulus; we may have to re-express the response, but the meat of the matter can usually be set out in a graph."

  - John W. Tukey (1962)

  - The future of data analysis.  *Annals of Mathematical Statistics*, 33:  1-67.


## Exploratory and confirmatory

- "Exploratory data analysis is detective work—numerical detective work—or counting detective work—or graphical detective work.”

  - John W. Tukey (1977)
  
  - *Exploratory Data Analysis*.  Addison-Wesley.

- "Exploratory data analysis is an attitude, a flexibility, and a reliance on display, NOT a bundle of techniques, and should be so taught.  Confirmatory data analysis, by contrast, is easier to teach and easier to computerize.  We need to teach both; to think about science and engineering more broadly; to be prepared to randomize and avoid multiplicity."

  - John W. Tukey (1980)
  
  - We need both exploratory and confirmatory.  *American Statistician*, 34: 23-25.

- "We’re talking about asking authors, ‘Is this hypothesis testing or exploratory?’ An exploratory study explores new questions rather than tests an existing hypothesis. But scientists have felt that they had to disguise an exploratory study as hypothesis testing and that is totally dishonest. I have no problem with true exploratory science. That is what I did most of my career. But it is important that scientists call it as such and not try to pass it off as something else."

  - Marcia McNutt (2016), now President of the National Academy of Sciences.
  
  - *Science*, 353: 116–119.

- "At one extreme, we can view the techniques of EDA \[Exploratory Data Analysis\] as a ritual designed to reveal patterns in a data set.  Thus, we may believe that naturally occurring data sets contain structure, that EDA is a useful vehicle for revealing the structure, and that revealed structure can sometimes be interpreted in the language of the subject matter that produced the data.  If we make no attempt to check whether the structure could have arisen by chance, and tend to accept the findings as gospel, then the ritual comes close to magical thinking.  None of this argues that exploration is useless or wrong.  Consulting statisticians canot be universal subject matter experts, and data often present striking patterns.  Such explorations have been, and continue to be an important part of science."

  - Persi Diaconis (1985)

  - Theories of data analysis:  From magical thinking through classical statistics.  In *Exploring Data Tables, Trends, and Shapes*, ed. by D. C. Hoaglin, F. Mosteller, and J. W. Tukey.  Wiley, pp. 1-36.

- "Exploratory data analysis:  The practice of studying data without preconceived notions as a means of obtaining ill-conceived ones.  The art of seeing a Rembrandt in a Jackson Pollock."

  - Stephen Senn (2007)

  - *Statistical Issues in Drug Development*, second edition.  Wiley.

## Correlation

- "...most correlation coefficients should never be calculated." 

  - John W. Tukey (1954)
  
  - Causation, regression, and path analysis. In *Statistics and Mathematics in Biology*, ed. by O. Kempthorne, T.A. Bancroft, J.W. Gowen, and J.L. Lush. Iowa State College Press, pp. 35-66.
  
- "Why then are correlation coefficients so attractive?  Only bad reasons seem to come to mind.  Worst of all, probably, is the absence of any need to think about units for either variable....Being so disinterested in our variables that we do not care about their units can hardly be desirable."

  - John W. Tukey (1969)
  
  - Analyzing data:  sanctification or detective work?  *American Psychologist*, 24 (2):  83-91.
  

## Statistical modeling

- "Essentially, all models are wrong, but some are useful." 

  - George E.P. Box
  
- "Very often, a statistician or scientist chooses a method because he or she is familiar with it, rather than because it is appropriate."

  - Peter J. Huber (2011)

  - *Data Analysis:  What Can Be Learned from the Past 50 Years*.  Wiley.

- "Live with the data before you plunge into modeling."

  - Leo Breiman (2001)
  
  - Statistical modeling:  the two cultures.  *Statistical Science*, 16:  199-231.
  
- "I wish we could learn to look at the data more directly, without the fictional models and priors. On the same wish-list: We should stop pretending to fix bad designs and inadequate measurements by modeling." 

  - David A. Freedman (1995)
  
  - Issues in the foundations of statistics: probability and statistical models. *Foundations of Science*, 1: 19-39.
  
- "I am deeply troubled by the current and past use of data models in applications, where quantitative conclusions are drawn and perhaps policy decisions are made."

  - Leo Breiman (2001)
  
  - Statistical modeling:  the two cultures.  *Statistical Science*, 16:  199-231.

- "One reason that statistical analyses are often not accepted or understood is that they are based on unsupported models."

  - Colin L. Mallows (1998)

  - The zeroth problem.  *The American Statistician*, 52:  1-9.
  
- "Unfortunately, much of the current work I see is neither interesting mathematics nor useful in practice. Worse, in its complexity, modern model building
seems to drive away from the truth into a fantasy land beyond objective reality....I feel that the believability of statistical analyses is at an all time low. If we do not stand up and say something the field will vanish."

  - Persi Diaconis (1998)
 
  - A place for philosophy?  The rise of modeling in statistical science.  *Quarterly of Applied Mathematics*, 4:  797-805.

- "Using the data to guide the data analysis is almost as dangerous as not doing so." 
 
  - Frank E. Harrell, Jr. (2001)
  
  - *Regression Modeling Strategies, with Applications to Linear Models, Logistic Regression, and Survival Analysis*. Springer.

- "Data will often point with almost equal emphasis at several possible models and it is important that the statistician recognize and accept this."

  - Peter McCullagh and John A. Nelder (1989)
  
  - *Generalized Linear Models*, second edition.  Chapman & Hall.

- "In my opinion, model users should be encouraged to think of models as tools that can aid in informing their judgment, rather than as substitutes for judgment that can best be employed mechanically."

  - Stephen K. McNees (1986)

  - Forecasting accuracy of alternative techniques:  a comparison of U.S. macroecnomic forecasts.  *Journal of Business and Economic Statistics*: 4:  5-15.
  
- "There is no methodology in traditional statistics for assessing the adequacy of a model!  The only thing orthodox frequentist theory can do about models is to reject them, and Bayesian statistics cannot even do that.  Nonrejection does not imply that the model is correct; it does not even tell one whether it adequately represents the data.  On the other hand, a rejected model might be perfectly adequate."

  - Peter J. Huber (2006)
  
  - Discussion, Tukey's paper after 40 years.  *Technometrics*, 48:  332-334.
  
- "Goodness-of-fit tests will reject even perfectly adequate models, once the sample size is large enough, simply because not every nook and cranny can and should be modeled."

  - Peter J. Huber (2011)

  - *Data Analysis:  What Can Be Learned from the Past 50 Years*.  Wiley.
  
- "We usually study the properties of estimators conditionally on the selected model, ruling out the possibility that the selected model might not be valid.  After all, the model selection is a random (data-dependent) process, but the (unknown) 'good' model is fixed, being a property of the studied phenomenon and oblivious to our study design and data collection process.  Model selection forces us to make a decision without considering the consequences of the errors that may have been made in the process.  We end up putting all our inferential eggs in one unevenly woven basket.  Depending on the purpose, an error of one kind may be innocuous or disastrous relative to an error of another kind.  The conditional probabilities of these two kinds of error, controlled in hypothesis testing, are often a poor indication of their gravity....We should bear in mind that models are our (statistical) invention, meant to assist us in the business of making inferences, and so it is rather disingenuous to shelter our inability to deliver work of high quality under the *caveat* 'Of course, if we do not identify the correct model...'.  (Your foot is at fault when a shoe does not fit well.)  My argument is not against models---they are indispensable---but against their unprincipled use....Many years ago, John Nelder called the established practice, which is still the norm today, as resulting in a 'junkyard of false positives'.  By ignoring model uncertainty, we are building a 'junyard of unsubstantiated confidence'."

  - Nicholas T. Longford (2005)
  
  - Model selection and efficiency---is 'which model...?' the right question?  *Journal of the Royal Statistical Society A*, 168:  469-472.
  
- "Applied statistics may be closer to epistemology than mathematics.  You have to question what you know, why you think you know it, and how confident you are (or should be) in that knowledge.  You must make simplifying assumptions and determine whether they are justified.  Statistical modeling is hard to do *well*.  It's easy to write down a model if you're not overly concerned with the accuracy of your results.  As the old saying goes, fools rush in where angels fear to tread."

  - John D. Cook (2022)

  - Quoted in K. Josic, A conversation with mathematical consultant John D. Cook.  *SIAM News*, 55 (5):  7-8 (June 2022).

## Categorical data

- "Cross-tabulation before regression." 

  - David A. Freedman (2008)
  
  - Randomization does not justify logistic regression. *Statistical Science*, 23: 237-249.

## Subgroup analyses

- "You should always do them but you should never believe them." 

  - Sir Richard Peto
  
## Robust and resistant statistics

- "The problem with it was and is that robustness is not a method, nor a collection of methods (although it is often misrepresented as such), but a concept stretching across methods, and calling for judgment more often than for theorems, proofs or algorithms, at least once the initial hurdles have been taken.  Judgment is required, for example, for the choice of models, tuning constants and breakdown levels.  Bootstrap had a faster initial rise, because it was falsely believed to be an algorithm that could be used in the absence of judgment, but now it is in the same slow boat.  I believe the reason is that judgment calls for thinking, and to think is difficult."

  - Peter J. Huber (1997)
  
  - Speculations on the path of statistics.  In *The Practice of Data Analysis:  Essays in Honor of John W. Tukey*, ed. by D. R. Brillinger, L. T. Fernholz, and S. Morgenthaler.  Princeton University Press, pp. 26-45.
  
- "Robustness is more than a bag of procedures.  It should be regarded as a state of mind:  a statistician should keep in mind that *all* aspects of a data analytic setup (experimental design, data collection, models, procedures) must be handled in such a way that minor deviations from the assumptions cannot have large effects on the results (a robustness problem), and that major deivations can be discovered (a diagnostic problem).  Only a small part of this can be captured by theorems and proofs, or by canned computer procedures."

  - Peter J. Huber (2011)

  - *Data Analysis:  What Can Be Learned from the Past 50 Years*.  Wiley.
  
## Statistical inferences

- "Notions of significance tests, confidence intervals, posterior intervals and all the formal apparatus of inference are valuable tools to be used as guides, but not in a mechanical way; they indicate the uncertainty that would apply under somewhat idealized, maybe very idealized, conditions and as such are often lower bounds to real uncertainty."

  - Sir David R. Cox (2001)

  - Comment on L. Breiman, Statistical modeling: the two cultures. *Statistical Science*, 16: 199-231.

- "At the risk of the obvious, inferences to imaginary populations are also imaginary."

  - Richard A. Berk & David A. Freedman (2003)
  
  - Statistical assumptions as empirical commitments.  In *Punishment, and Social Control:  Essays in Honor of Sheldon Messenger*, 2d ed., ed. by T. G. Blomberg and S. Cohn.  Aldine de Gruyter, pp. 235-254.
  
- "On the basis of the same data, you cannot both discover a feature and perform a meaningful statistical test for its presence....it is no longer possible to calculate reliable P-values *after* one has looked at the data -- unless they are based on fresh data, they may be worse than useless, namely misleading."

  - Peter J. Huber (2011)

  - *Data Analysis:  What Can Be Learned from the Past 50 Years*.  Wiley.

- "Classical mathematical statistics....seeks to interpret patterns as chance fluctuations.  In its most rigid formulation, we decide upon models and hypotheses *before* seeing the data.  Then we compute estimates and carry out tests of our assumptions.  Classical statistics offers an antidote for some of the problems of magical thinking.  However, as a description of what a real scientist does when confronting a real, rich data base, it seems as far off as a primitive ritual....none of the classical theories of statistics comes close to capturing what a real scientist does when exploring new data in a real scientific problem.  All formal theories---Neyman-Pearson, decision-theoretic, Bayesian, Fisherian, and others---work with prespecified probability models."

  - Persi Diaconis (1985)

  - Theories of data analysis:  From magical thinking through classical statistics.  In *Exploring Data Tables, Trends, and Shapes*, ed. by D. C. Hoaglin, F. Mosteller, and J. W. Tukey.  Wiley, pp. 1-36.

- "It must be emphasized that if independent tests are to be compounded it is absolutely essential that this be decided, and the tests to be compounded be fully specified, before viewing the sample. This is, of course, an indispensable condition for the validity of any test of significance. An investigator who after inspecting the data decides what to test or how to make the test can, by virtue of the fact that any sample has unique characteristics, disprove any hypothesis. To put the point another way: agreement between a sample and a hypothesis based on that sample is purely tautological and proves nothing but accuracy in reading and restating the data of the sample. Agreement is significant only in so far as it occurs despite freedom for disagreement. (This does not mean, of course, that hypotheses formulated after examining the sample are useless--they are invaluable; it simply means that, however well they accord with the sample from which derived, they can be regarded only as unsubstantiated hypotheses for further investigation.)"

  - W. Allen Wallis (1942)

  - Compounding probabilities from independent significance tests.  *Econometrica*, 10:  229-248.

- "The econometric art as it is practiced at the computer terminal involves fitting many, perhaps thousands, of statistical models. One or several that the researcher finds pleasing are selected for reporting purposes. This searching for a model is often well intentioned, but there can be no doubt that such a specification search invalidates the traditional theories of inference. The concepts of unbiasedness, consistency, efficiency, maximum-likelihood estimation, in fact, all the concepts of traditional theory, utterly lose their meaning by the time an applied researcher pulls from the bramble of computer output the one thorn of a model he likes best, the one he chooses to portray as a rose.  The consuming public is hardly fooled by this chicanery...Hardly anyone takes data analyses seriously. Or perhaps more accurately, hardly anyone takes anyone else's data analyses seriously. Like elaborately plumed birds who have long since lost the ability to procreate but not the desire, we preen and strut and display our *t*-values....Because both the sampling distribution and the prior distribution are actually *opinions* and not *facts*, a statistical inference is and must forever remain an *opinion*."

  - Edward E. Leamer (1983)

  - Let's take the con out of econometrics.  *The American Economic Review*, 73:  31-43.

- "Statistical theory as taught in books is valid and leads to operationally verifiable tests and criteria for an enumerative study.  Not so with an analytic problem, as the conditions of the experiment will not be duplicated in the next trial.  Unfortunately most problems in industry are analytic."

  - W. Edwards Deming (1980)

  - Dedication for the reprint of *Economic Control of Quality of Manufactured Product* by W. A. Shewhart (Milwaukee:  Quality Press).

- "And because what we observe is not the outcome of a stationary process, conventional statistical inference rarely apples and forecasts are often based on shifting sands."

  - John Kay and Mervyn King (2020)

  - *Radical Uncertainty:  Decision-Making Beyond the Numbers* (New York:  W. W. Norton).

## Null hypothesis significance testing (NHST)

- "Null hypotheses of no difference are usually known to be false before the data are collected....when they are, their rejection or acceptance simply reflects the size of the sample and the power of the test, and is not a contribution to science."

  - I. Richard Savage (1957)
  
  - Nonparametric statistics.  *J. Amer. Stat. Assoc.*, 52:  331-334.

- "We do not perform an experiment to find out if two varieties of wheat or two drugs are equal.  We know in advance, without spending a dollar on an experiment, that they are not equal.  The difference beween two treatments or between two areas or two groups of people, will show up as 'significantly different' if the experiment be conducted through a sufficient number of trials, even though the difference be so small that it is of no scientific or economic consequence."

  - W. Edwards Deming (1975)
  
  - On probability as a basis for action.  *American Statistician*, 29:  146-152.
  
- "Statisticians classically asked the wrong question--and were willing to answer with a lie, one that was often a downright lie.  They asked 'Are the effects of A and B different?' and they were willing to answer 'no'.  All we know about the world teaches us that the effects of A and B are always different--in some decimal place--for any A and B.  Thus asking 'Are the effects different?' is foolish."

  - John W. Tukey (1991)
  
  - The philosphy of multiple comparisons.  *Statistical Science*, 6:  100-116.

- NHST "often amounts to uncertainty laundering. Any study, no matter how poorly designed and conducted, can lead to statistical significance and thus a declaration of truth or falsity. NHST was supposed to protect researchers from over-interpreting noisy data. Now it has the opposite effect."

  - Blakeley B. McShane and Andrew Gelman (2017)
  
  - Five ways to fix statistics.  *Nature*, 551:  557-559.
  
- "Dr. Shewhart was well aware that the statistician's levels of significance furnish no measure of belief in a prediction.  Probability has use; tests of significance do not."

  - W. Edwards Deming (1986)

  - Foreword to the reprint of *Statstical Method from the Viewpoint of Quality Control* by Walter A. Shewhart (New York:  Dover).

## Confidence intervals

- "On the whole, however, tests of significance are less frequently useful in experimental work than confidence limits.  In many experiments it seems obvious that the different treatments must have produced some difference, however small, in effect.  Thus the hypothesis that there is *no* difference is unrealistic; the real problem is to obtain estimates of the sizes of the differences."

  - William G. Cochran and Gertrude M. Cox (1957)

  - *Experimental Designs*, second edition.  Wiley.

- "Thus, a frequent mistake is to calculate a confidence interval to contain the population mean when the problem requires a tolerance interval or a prediction interval.  At other times, a tolerance interval is used when a prediction interval is needed.  Such confusion is understandable, because most texts on statistics generally discuss confidence intervals, occasionally make reference to tolerance intervals, but generally consider prediction intervals only in the context of regression analysis."

  - Gerald J. Hahn and William Q. Meeker (1991)

  - *Statistical Intervals:  A Guide for Practitioners*.  Wiley.

- "I am referring to Dr. Neyman's confidence limits. I am not at all sure that the 'confidence' is not a 'confidence trick.'"

  - Sir Arthur Lyon Bowley (1934)

  - Discussion of Jerzy Neyman's paper, On the two different aspects of the representative method:  the method of stratified sampling and the method of purposive selection, *Journal of the Royal Statistical Society*, 97:  558-625.

## Laboratory quality control

- "Most directors of research hold to the opinion, and rightly so, that they are engaged in research, not production.  Deviating from this would be bad for all concerned; yet it is helpful to realize what is the greatest production activity of any research group it is the *production of measurement*.  There are few research projects in which actual measurement, together with the preapration of instruments and samples, does not represent a substantial part of the effort.  Most of this measurement is of a production character --- yet too often it is not operated as such.  Sometimes it is operated too much so, but this is another matter."

  - John W. Tukey (1953)
  
  - The growth of experimental design in a research laboratory.  In *Research Operations in Industry: Papers Delivered at the Third Annual Conference on Industrial Research, June 1952. With Selected Papers from the First and Second Conferences*, ed. by D. B. Hertz.  Columbia University Press, pp. 303-313.


## Statistical conclusions

- "Absence of evidence is not evidence of absence."

  - Unknown

- "I remarked earlier on the tendency of economists to get the result their theory tells them to expect. In a talk I gave at the University of Virginia in the early 1960s, at which Warren Nutter was, I think, present, I said that if you torture the data enough, nature will always confess, a saying which, in a somewhat altered form, has taken its place in the statistical literature."

  - Ronald Coase (1981)

  - *How Should Economists Choose?* (Third G. Warren Nutter Lecture in Political Economy, American Enterprise Institute, Nov. 18, 1981).  American Enterprise Institute for Public Policy Research, 1982.

- "Confirmation comes from repetition.  Any attempt to avoid this statement leads at least to failure and more probably to destruction....Repetition is the basis for judging variability and significance and confidence....Are we prepared to look for quantitative constancies in psychology?   To reward those that find them?  To answer 'yes' to such questions, rather than to assume such constancies are natural laws not requiring checking, demands an emphasis on breadth of data, on repetition under different parallel circumstances, of which we have seen far too little."

  - John W. Tukey (1969)
  
  - Analyzing data:  sanctification or detective work?  *American Psychologist*, 24 (2):  83-91.

- "Generally, replication and prediction of new results provide a harsher and more useful validating regime than statistical testing of many models on one data set.  Fewer assumptions are needed, there is less chance of artifact, more kinds of variation can be explored, and alternative explanations can be ruled out."

  - David A. Freedman (1991)
  
  - Statistical models and shoe leather.  *Sociological Methodology*, 21:  291-313.

- "Comparison between results from two or more unrelated sources of information may provide a more convincing confirmation of the correctness of an interpretation than any statistical test."

  - Peter J. Huber (2011)

  - *Data Analysis:  What Can Be Learned from the Past 50 Years*.  Wiley.

- "Replication on fresh data, preferably by another group of experimenters, is a mainstay of the 'scientific method'.  If done skillfully, replication can eliminate all difficulties with extensive exploration."

  - Persi Diaconis (1985)

  - Theories of data analysis:  From magical thinking through classical statistics.  In *Exploring Data Tables, Trends, and Shapes*, ed. by D. C. Hoaglin, F. Mosteller, and J. W. Tukey.  Wiley, pp. 1-36.

- "The responsibility lies more heavily on statisticians than on any other professional to make sure that their descriptions of the data not be subject to misinterpretation.  This is what has given our discipline its bad name.  We are all damned liars, because what we do is often presented obscurely and so does not convince.  Of course some of what we do is obscure even to ourselves."

  - Colin L. Mallows (1983)
  
  - Data description.  In *Scientific Inference, Data Analysis, and Robustness*, ed. by G. E. P. Box, T. Leonard, and C.-F. Wu.  Academic Press, 135-151.

- "So statistical methods look like magic, with results pulled out of thin air."

  - Colin L. Mallows (1998)
  
  - The zeroth problem.  *The American Statistician*, 52:  1-9.

- "What should experimental statistics as a whole do about systematic errors?  Should we change from '95 percent confidence' to '5 percent diffidence' and impress on our clients that more diffidence has to be added because of systematic errors?  Have we been overselling our clients on the confidence with which they should accept the results of our analyses?  Is this why physics is the most-resistant of all the sciences to the penetration of statistics?"

  - John W. Tukey (1954)

  - Unsolved problems of experimental statistics.  *Journal of the American Statistical Association*, 49:  706-731.

- "How does one recognize a good statistical analysis?  Most evaluation of specific data analysis is anecdotal.  An example is briefly described, and the illustrated use of the technique is pronounced successful.  Critics find it all too easy to shift the burden of proof by pronouncing that most statistical analysis is useless or misleading.  The situation is paradoxical because data collection and analysis is a basic tool for evaluation, so that statisticians should be well equipped to construct systems for measuring and analyzing their own performance."

  - Arthur P. Dempster (1983)
  
  - Purposes and limitations of data analysis.  In *Scientific Inference, Data Analysis, and Robustness*, ed. by G. E. P. Box, T. Leonard, and C.-F. Wu.  Academic Press, 117-133.

- "But a word of caution is that statistics users often equate the word "test" with statistical testing....As a statistician, I feel honored that statistics users have this kind of confidence in my profession.  On the other hand, I am also deeply troubled, because in most cases a scientific theory of cause-and-effect has to be tested by the scientists themselves, not by statisticians.  Statisticians have indeed made important contributions to numerous instances of scientific testing; but their role is often blown out of proportion."

  - Chamont Wang (1993)

  - *Sense and Nonsense of Statistical Inference:  Controversy, Misuse, and Subtlety*.  Marcel Dekker.

- "As statisticians we must insist upon more than one kind of conclusion, upon the difference between 'statistical conclusions' and 'experimenter's conclusions'.  A 'statistical conclusion' applies to the *actual* conditions of the experiment.  If a consistent blunder were made, if the instruments or measurements yield substantial systematic errors (they will always have some systematic errors, though we may hope that these are small), if the measurements were reduced according to a theory which is incomplete in some important way (it will always be incomplete to a certain extent), if the conditions or measurements were incorrectly recorded, if the importance of important variables were not recognized (so that their values were not recorded or reported), the stated conclusions are likely be wrong.  Errors for such reasons are not to be charged against *statisical* conclusions.  But experimenter's conclusions, be they physical conclusions, chemical conclusions, biological conclusions, or engineering conclusions, must take account of all these possibilities.  In most areas of experiment or observation it will be either deirable or necessary for the experimenter to make specific allowance, beyond the statistically recongnizable uncertainty, for such deviations of the actual situation from the supposed situation.  For this reason, his conclusions will be weaker than the than the statistical ones.  The difference, which arises from what may loosely be called the problem of systematic error, is an important challenge to the statistician."

  - John W. Tukey (1960)

  - Conclusions vs. decisions.  *Technometrics*, 2:  423-433.

- "Quick, easy decisions and cut-and-dry conclusions based on statistical results are described, implicitly de-emphasizing the need to wrestle critically with uncertainty, and contributing to the widespread phenomenon of over-selling what statistical inference and methods provide. The over-selling and over-stating happens in research proposals, publications, media reports of research findings, and in books meant to be attractive to nonstatisticians.  There are so many positive implications of the statistical revolution, but there are also negative consequences, and that should be part of the message statisticians are sending to the world; people have bought into the value, but without an in-depth understanding of the implications. Humans are hungry to rid a problem of uncertainty and come away with a cut-and-dry answer, and statisticians should be wary of reinforcing the misunderstanding that the practice of statistics is just calculations and answers—just simply 'number crunching.' It is difficult to comprehend the limitations of something we do not fully understand and there is a tendency to simply trust that which seems too complicated or is beyond our formal education. Therefore, there is a trust placed on those individuals who do understand the foundations and details (statisticians) to convey limitations clearly and often; though this is getting more difficult as statisticians continue to lose control over methods...."

  - Megan D. Higgs (2019)
  
  - Review of *Errors, Blunders, and Lies:  How to Tell the Difference*, by David S. Salsburg (Chapman & Hall/CRC Press, 2017).  *The American Statistician*, 73:  95-96.

## Statistical consulting

- "A simple and almost ludicrous definition of the error of the third kind is *the error committed by giving the right answer to the wrong problem*.  In defining it this way we are allowing the statistician the benefit of the doubt by rejecting the possibility that he would give the wrong answer to the wrong question."

  - Allyn W. Kimball (1957)
  
  - Errors of the third kind in statisical consulting.  *J. Amer. Stat. Assoc.*, 52:  133-142.

- "Far better an approximate answer to the right question, which is often vague, than an exact answer to the wrong question, which can always be made precise." 

  - John Tukey (1962)
  
  - The future of data analysis. *Annals of Mathematical Statistics*, 33: 1-67.

- "To consult the statistician after an experiment is finished is often merely to ask him to conduct a *post mortem* examination.  He can perhaps say what the experiment died of."

  - Ronald A. Fisher (1938)
  
  - Presidential Address.  *Sankhya: The Indian Journal of Statistics*, 4 (1):  14-17.
  
- "The statistician who supposes that his main contribution to the planning of an experiment will involve statistical theory, finds repeatedly that he makes his most valuable contribution simply by persuading the investigator to epxlain why he wishes to do the experiment, by persuading him to justify the experimental treatments, and to explain why it is that the experiment, when completed, will assist him in his research."

  - Gertrude M. Cox (1951)

  - Lecture at the U.S. Department of Agriculture, Washington, D.C., 11 January 1951.  Quoted by W. Edwards Deming (1960), *Sample Design in Business Research*.  Wiley.

- "By an *end* we refer to real purposes of the user of the statistical technique.  These purposes are often unformulated, and their partial formulation often requires the statistician to 'psychoanalyze' his client (in the writer's view this is one of the most important functions of the statistical consultant!)."

  - John W. Tukey (1954)

  - Unsolved problems of experimental statistics.  *Journal of the American Statistical Association*, 49:  706-731.

- "Once the statistician gives up the hubris of being 'the decider', he or she can seize a vital role, helping to make science and technology function better, because groups and people now understand the quantitative aspects of the strenghts of each other's results more clearly.  The qualitative aspects, frequently even more important, still have to be judged by those who know the field."  

  - Persi Diaconis (1985)

  - Theories of data analysis:  From magical thinking through classical statistics.  In *Exploring Data Tables, Trends, and Shapes*, ed. by D. C. Hoaglin, F. Mosteller, and J. W. Tukey.  Wiley, pp. 1-36.


- "If you don't know whether you are a good statistician or not, here is a simple test:  If your name is Joe Blow and there is a very tough investigation coming up, and the engineers and scientists say, 'We've got to have Joe on the team,' then you will have arrived."

  - George E. P. Box (1998)

  - Statistics as a catalyst to learning by scientific method,  Response to the discussion, *Journal of Quality Technology*, 31:  67-72.

- "It's easier to get involved than it is to extricate yourself."

  - John C. Bailar, III (1976)
  
  - Bailar's laws of data analysis.  *Clinical Pharmacology and Therapeutics*, 20:  113-119.

## Probability

- "It is curious how often the most acute and powerful intellects have gone astray in the calculation of probabilities."

  - William Stanley Jevons (1877)

  - *The Principles of Science:  A Treatise on Logic and Scientific Method*, second edition.  Macmillan.

- "For thirty years, I have found Bayesian statistics to be a rich source of mathematical questions.  However, I no longer see it as the preferred way to do applied statistics, because I find that uncertainty can rarely be quantified as probability."

  - David A. Freedman (1991)

  - A rejoinder to Berk, Blalock, and Mason.  *Sociological Methodology*, 21:  353-358.

- "Bayesian techniques assume we know all the alternate possible states of nature, yet the great gains in knowledge come when we find that our 'knowledge' was quite wrong."

  - John W. Tukey (1972)
 
  - Data analysis, computation, and mathematics.  *Quarterly of Applied Mathematics*, 30:  51-65.

- "Bayes' theorem is not the only way that probability shifts in response to new evidence."

  - Persi Diaconis (1985)

  - Theories of data analysis:  From magical thinking through classical statistics.  In *Exploring Data Tables, Trends, and Shapes*, ed. by D. C. Hoaglin, F. Mosteller, and J. W. Tukey.  Wiley, pp. 1-36.

- "Probability does not exist."

  - Bruno de Finetti (1970)
  
  - *Teoria delle Probabilita*.  Einaudi.
  
- "I doubt that the theory of probability can be reduced to either mathematics or computing, though there are people who claim to have done so."

  - Richard W. Hamming (1991)
  
  - *The Art of Probability for Scientists and Engineers*.  Perseus.

- "The statistician's report to management should not talk about probabilities.  It will merely give outside margins of error for the results of chief importance.  Administrators are not interested in probabilities; they need to know what figure they can use and within what range they may depend on it."

  - W. Edwards Deming (1960)

  - *Sample Design in Business Research*.  Wiley.

- "I...shall continue to use the words 'data analysis', in part to indicate that we can take probability seriously, or leave it alone, as may from time to time be appropriate or necessary."

  - John W. Tukey (1972)

  - Data analysis, computation, and mathematics.  *Quarterly of Applied Mathematics*, 30:  51-65.

- "The appeal of probability theory is understandable.  But we suspect the reason that such mathematics was, as we shall see, not developed until the seventeenth century is that few real-world problems can properly be represented in this way.  The most compelling extension of probabilistic reasoning is to situations where the possible outcomes are well defined, the underlying processes which give rise to them change little over time, and there is a wealth of historic information."

  - John Kay and Mervyn King (2020)

  - *Radical Uncertainty:  Decision-Making Beyond the Numbers* (New York:  W. W. Norton).

- "Probability calculations are very precise, and for that reason alone they are also of very limited use. Outside of gambling, financial applications, and some physical and engineering problems -- and even these are limited -- mathematical probability is of little direct use for reasoning with uncertainty."

  - Harry Crane (2020)

  - Naive probabilism.  [Researchers.One](http://www.researchers.one/article/2020-03-9)

## Mathematics

- "The miracle of the appropriateness of the language of mathematics for the formulation of the laws of physics is a wonderful gift which we neither understand nor deserve."

  - Eugene P. Wigner (1960)
  
  - The unreasonable effetiveness of mathematics in the natural sciences.  *Communications in Pure and Applied Mathematics*, 13:  1-14.

- "Does anyone believe that the difference between the Lebesgue and Riemann integrals can have physical significance, and that whether say, an airplane would or would not fly could depend on this difference? If such were claimed, I should not care to fly in that plane."

  - Richard W. Hamming (1998)
  
  - Mathematics on a distant planet.  *American Mathematical Monthly*, 105:  640-650.

- "[M]athematics is seductively easy compared with data analysis."

  - Colin Mallows (2006)
  
  - Tukey's paper after 40 years.  *Technometrics*, 48:  319-325.

- "To the extent that pieces of *mathematical statistics* fail to contribute, or are not intended to contribute, even by a long and tortuous chain, to the practice of data analysis, they must be judged as pieces of *pure* mathematics, and criticized according to its purest standards.  Individual parts of mathematical statistics must look for their justification toward either data anlaysis or pure mathematics.  Work which obeys neither master, and there are those who deny the rule of both for their own work, cannot fail to be transient, to be doomed to sink out of sight.  And we must be careful that, in its sinking, it does not take with it work of continuing value."

  - John W. Tukey (1962)

  - The future of data analysis.  *Annals of Mathematical Statistics*, 33:  1-67.

- "All to often, statistical theory is miscalled mathematical statistics, about which too many practitioners (even some them Englishmen!) take the dangerous view that work can be good mathematical statistics without being either good mathematics or good statistics."

  - John W. Tukey (1972)

  - Data analysis, computation, and mathematics.  *Quarterly of Applied Mathematics*, 30:  51-65.

- "I am not saying that the mathematical aspects of statistics are unimportant, but that the reason that statistics is not a mainstream subject is because it has got lost in a mathematical tributary.  It would be helpful if it was categorized and recognized a uniquely important science rather than as one of the (lesser) branches of applied mathematics."

  - G. E. P. Box (2006)

  - *Improving Almost Anything:  Ideas and Essays*, revised edition.  Wiley.  

- "If we waited for all the epsilons and deltas to be supplied before we used techniques that statistical common sense suggests, we would be technical paupers. Mathematical rigor is desirable, but its absence is not a just basis for rejection. To adopt a stricter policy would be to succumb to a different kind of rigor."

  - Forman S. Action (1959)
  
  - *Analysis of Straight-Line Data*.  Wiley.

- "I shall avoid, as much as I can, those questions which, though they have elicited the skill of mathematicians, have not enlarged our knowledge of science."

  - James Clerk Maxwell (1873)

  - *A Treatise on Electricity and Magnetism*.  Clarendon.

## Computing

- "The purpose of computing is insight, not numbers."

  - Richard W. Hamming (1962)
  
  - *Numerical Methods for Scientists and Engineers*.  McGraw-Hill.

- "Not all scientists are even informed users of the commercial packages they use (e.g., statistical analysis software)."

  - Marcia McNutt (2020)
  
  - Self-correction by design.  *Harvard Data Science Review*, 2.4.

- "Computers have released us from having to teach the nitty-gritty of our analytic techniques.  But this has mainly served to highlight the emperor's new clothes, namely the general lack of practical relevance of what we had been teaching."

  - Andrew S. C. Ehrenberg (1990)
  
  - A hope for the future of statistics:  MSOD.  *The American Statistician*, 44:  195-196.

## Statisticians, Physicists, and Social Science

- "The best thing about being a statistician is that you get to play in everyone's backyard."

  - John W. Tukey

- "Somebody was telling me yesterday that they're making 1400 physics Ph.D.'s a year in this country and there aren't going to be that many who do theoretical physics [after they graduate].  On the other hand, theoretical physicists, it's been well established, can be converted to almost anything....And I don't think we'd get away with training 1400 Ph.D.'s a year in statistics and have most of them leave and go into all sorts of other things."

  - John W. Tukey (1997)
  
  - A conversation with John Tukey.  In *The Practice of Data Analysis:  Essays in Honor of John W. Tukey*, ed. by D. R. Brillinger, L. T. Fernholz, and S. Morgenthaler.  Princeton University Press, pp. 26-45.
  
- "A future professional statistician needs a solid foundation in mathematics and in a science.  One reason for the first requirement is the actual need for mathematical proficiency, but only in part; it is just as important to inure him or her against being intimidated by mathematical fireworks.  The second provides the much needed understanding of the spirit prevailing in the sciences.  A very old-fashioned traditional university education in physics, augmented by probability and statistics courses, may come closest to this ideal."

  - Peter J. Huber (1997)
  
  - Speculations on the path of statistics.  In *The Practice of Data Analysis:  Essays in Honor of John W. Tukey*, ed. by D. R. Brillinger, L. T. Fernholz, and S. Morgenthaler.  Princeton University Press, pp. 175-192.

- "Are physical scientists and engineers too foolish to recognize the value of statistics?  I don't think so.  Rather I think they understand that the basic philosophy that motivates much of the statistics taught in universities is not appropriate for what they do."

  - G. E. P. Box (2006)

  - *Improving Almost Anything:  Ideas and Essays*, revised edition.  Wiley.

- "Statistics has definitely evolved into a field in which people can do their work without actually seeing and doing applications."

  - William M. Mason (1991)

  - Freedman is right as far as he goes, but there is more, and it's worse.  Statisticians could help.  *Sociological Methodology*, 21:  337-351.  

- "Although statistics departments in universities are now commonplace there continues to be a severe shortage of statisticians competent to deal with real problems.  But such are needed."

  - G. E. P. Box (1976)

  - Science and statistics.  *Journal of the American Statistical Association*, 71:  791-799.

- "Biostatistician:  One who has neither the intellect for mathematics nor the commitment for medicine but likes to dabble in both."

  - Stephen Senn (2007)

  - *Statistical Issues in Drug Development*, second edition.  Wiley.


- "Thou shalt not sit with statisticians nor commit a social science."

  - W. H. Auden (1946)
  
  - *Under Which Lyre*

## Should I be a statistician?

Richard Olshen:  "Leo, you have a record of wide-ranging interest in and contributions to statistics and statistical computing and probability and pedagogy.  What advice would you give to a young person today who wants to continue in your traditions?  What should he or she study and why?"

Leo Brieman:  "Well Richard, I'm torn in a way because what I might even tell them is, 'Don't go into statistics.'  My feeling is, to some extent, that academic statistics may have lost its way."

(From A Conversation with Leo Breiman, *Statistical Science*, 16:  184-198.)

## Miscellaneous

See [Meredith G. Warshaw's Field Guide to Atypical Statistics](http://www.uniquelygifted.org/fieldguide.htm).

## Note on Github flavored markdown

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).


